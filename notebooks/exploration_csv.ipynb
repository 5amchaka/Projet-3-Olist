{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des CSV bruts Olist\n",
    "\n",
    "Ce notebook analyse en profondeur les 9 fichiers CSV du dataset Olist Brazilian E-commerce.\n",
    "L'objectif est de documenter les observations qui motivent les choix de modélisation\n",
    "du star schema (voir `docs/csv_to_star_schema.md`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from src.etl.extract import load_all_raw\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_all_raw()\n",
    "print(f\"{len(raw)} datasets chargés : {list(raw.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau récapitulatif\n",
    "summary = pd.DataFrame({\n",
    "    \"lignes\": {k: df.shape[0] for k, df in raw.items()},\n",
    "    \"colonnes\": {k: df.shape[1] for k, df in raw.items()},\n",
    "    \"mémoire (MB)\": {k: round(df.memory_usage(deep=True).sum() / 1e6, 2) for k, df in raw.items()},\n",
    "    \"doublons exacts\": {k: df.duplicated().sum() for k, df in raw.items()},\n",
    "})\n",
    "summary.style.format({\"lignes\": \"{:,}\", \"mémoire (MB)\": \"{:.2f}\", \"doublons exacts\": \"{:,}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Profil de chaque dataset\n",
    "\n",
    "Pour chacun des 9 CSV : types, stats descriptives, valeurs manquantes, doublons et valeurs uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_dataset(name: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"Affiche un profil complet d'un dataset.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"  {name.upper()}  ({df.shape[0]:,} lignes × {df.shape[1]} colonnes)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Info types\n",
    "    print(\"\\n--- Types et non-null ---\")\n",
    "    print(df.dtypes.to_frame(\"dtype\").join(df.notnull().sum().to_frame(\"non_null\")))\n",
    "\n",
    "    # Stats numériques\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns\n",
    "    if len(num_cols) > 0:\n",
    "        print(\"\\n--- Statistiques numériques ---\")\n",
    "        display(df[num_cols].describe().round(2))\n",
    "\n",
    "    # Aperçu\n",
    "    print(\"\\n--- Aperçu (5 premières lignes) ---\")\n",
    "    display(df.head())\n",
    "\n",
    "    # Valeurs uniques\n",
    "    print(\"\\n--- Valeurs uniques par colonne ---\")\n",
    "    print(df.nunique().to_frame(\"n_unique\"))\n",
    "\n",
    "    # Valeurs manquantes\n",
    "    missing = df.isnull().mean() * 100\n",
    "    if missing.sum() > 0:\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(df.columns) * 0.3)))\n",
    "        missing.sort_values().plot.barh(ax=ax, color=\"salmon\")\n",
    "        ax.set_xlabel(\"% manquant\")\n",
    "        ax.set_title(f\"{name} — Taux de valeurs manquantes\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n✓ Aucune valeur manquante\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in raw.items():\n",
    "    profile_dataset(name, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Relations et cardinalités\n",
    "\n",
    "### Schéma des FK entre les 9 CSV\n",
    "```\n",
    "geolocation.zip_code_prefix ←── customers.customer_zip_code_prefix\n",
    "geolocation.zip_code_prefix ←── sellers.seller_zip_code_prefix\n",
    "customers.customer_id ←──────── orders.customer_id\n",
    "orders.order_id ──────────────→ order_items.order_id\n",
    "orders.order_id ──────────────→ order_payments.order_id\n",
    "orders.order_id ──────────────→ order_reviews.order_id\n",
    "products.product_id ←────────── order_items.product_id\n",
    "sellers.seller_id ←──────────── order_items.seller_id\n",
    "products.product_category_name → category_translation.product_category_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vérification des cardinalités --\n",
    "\n",
    "orders = raw[\"orders\"]\n",
    "customers = raw[\"customers\"]\n",
    "order_items = raw[\"order_items\"]\n",
    "order_payments = raw[\"order_payments\"]\n",
    "order_reviews = raw[\"order_reviews\"]\n",
    "products = raw[\"products\"]\n",
    "sellers = raw[\"sellers\"]\n",
    "geolocation = raw[\"geolocation\"]\n",
    "cat_trans = raw[\"category_translation\"]\n",
    "\n",
    "print(\"=== Cardinalités ===\")\n",
    "print(f\"\\norders.customer_id → customers.customer_id\")\n",
    "print(f\"  orders uniques customer_id : {orders['customer_id'].nunique():,}\")\n",
    "print(f\"  customers uniques          : {customers['customer_id'].nunique():,}\")\n",
    "print(f\"  → Relation N:1 (chaque commande a 1 client)\")\n",
    "\n",
    "print(f\"\\norder_items.order_id → orders.order_id\")\n",
    "items_per_order = order_items.groupby(\"order_id\").size()\n",
    "print(f\"  items par commande — moy: {items_per_order.mean():.2f}, max: {items_per_order.max()}\")\n",
    "print(f\"  → Relation N:1 (plusieurs items par commande)\")\n",
    "\n",
    "print(f\"\\norder_payments.order_id → orders.order_id\")\n",
    "pays_per_order = order_payments.groupby(\"order_id\").size()\n",
    "print(f\"  paiements par commande — moy: {pays_per_order.mean():.2f}, max: {pays_per_order.max()}\")\n",
    "print(f\"  → Relation N:1 (plusieurs paiements possibles par commande)\")\n",
    "\n",
    "print(f\"\\norder_reviews.order_id → orders.order_id\")\n",
    "reviews_per_order = order_reviews.groupby(\"order_id\").size()\n",
    "print(f\"  reviews par commande — moy: {reviews_per_order.mean():.2f}, max: {reviews_per_order.max()}\")\n",
    "multi_review = (reviews_per_order > 1).sum()\n",
    "print(f\"  commandes avec >1 review : {multi_review}\")\n",
    "print(f\"  → Relation N:1 (normalement 1 review par commande, mais {multi_review} exceptions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Orphelins : FK sans correspondance dans la table parent --\n",
    "\n",
    "checks = [\n",
    "    (\"orders.customer_id\", orders[\"customer_id\"], customers[\"customer_id\"]),\n",
    "    (\"order_items.order_id\", order_items[\"order_id\"], orders[\"order_id\"]),\n",
    "    (\"order_items.product_id\", order_items[\"product_id\"], products[\"product_id\"]),\n",
    "    (\"order_items.seller_id\", order_items[\"seller_id\"], sellers[\"seller_id\"]),\n",
    "    (\"order_payments.order_id\", order_payments[\"order_id\"], orders[\"order_id\"]),\n",
    "    (\"order_reviews.order_id\", order_reviews[\"order_id\"], orders[\"order_id\"]),\n",
    "]\n",
    "\n",
    "print(\"=== Vérification des orphelins ===\")\n",
    "for label, child_col, parent_col in checks:\n",
    "    orphans = child_col[~child_col.isin(parent_col)].nunique()\n",
    "    status = \"✓ OK\" if orphans == 0 else f\"⚠ {orphans} orphelins\"\n",
    "    print(f\"  {label:35s} → {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Distribution du nombre de lignes enfant par parent --\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "items_per_order.plot.hist(bins=range(1, items_per_order.max() + 2), ax=axes[0], color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0].set_title(\"Items par commande\")\n",
    "axes[0].set_xlabel(\"Nombre d'items\")\n",
    "\n",
    "pays_per_order.plot.hist(bins=range(1, pays_per_order.max() + 2), ax=axes[1], color=\"coral\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Paiements par commande\")\n",
    "axes[1].set_xlabel(\"Nombre de paiements\")\n",
    "\n",
    "reviews_per_order.plot.hist(bins=range(1, reviews_per_order.max() + 2), ax=axes[2], color=\"mediumseagreen\", edgecolor=\"white\")\n",
    "axes[2].set_title(\"Reviews par commande\")\n",
    "axes[2].set_xlabel(\"Nombre de reviews\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylabel(\"Nombre de commandes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Analyses approfondies par dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 geolocation — Dédoublonnage\n",
    "\n",
    "Le CSV contient ~1M de lignes pour ~19k zip_code_prefix uniques.\n",
    "Plusieurs lignes par zip avec des coordonnées et noms de ville variables.\n",
    "→ Justifie l'agrégation médiane (coordonnées) + mode (ville/état)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = raw[\"geolocation\"]\n",
    "print(f\"Lignes totales : {len(geo):,}\")\n",
    "print(f\"zip_code_prefix uniques : {geo['geolocation_zip_code_prefix'].nunique():,}\")\n",
    "\n",
    "# Nombre de lignes par zip\n",
    "rows_per_zip = geo.groupby(\"geolocation_zip_code_prefix\").size()\n",
    "print(f\"\\nLignes par zip — moy: {rows_per_zip.mean():.1f}, médiane: {rows_per_zip.median():.0f}, max: {rows_per_zip.max()}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "rows_per_zip.clip(upper=100).plot.hist(bins=50, ax=ax, color=\"steelblue\", edgecolor=\"white\")\n",
    "ax.set_title(\"Distribution du nombre de lignes par zip_code_prefix (clippé à 100)\")\n",
    "ax.set_xlabel(\"Nombre de lignes\")\n",
    "ax.set_ylabel(\"Nombre de zips\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabilité des coordonnées pour un même zip\n",
    "coord_variability = geo.groupby(\"geolocation_zip_code_prefix\").agg(\n",
    "    lat_std=(\"geolocation_lat\", \"std\"),\n",
    "    lng_std=(\"geolocation_lng\", \"std\"),\n",
    ").dropna()\n",
    "\n",
    "print(f\"Écart-type des coordonnées par zip (sur {len(coord_variability):,} zips avec >1 ligne) :\")\n",
    "display(coord_variability.describe().round(4))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "coord_variability[\"lat_std\"].clip(upper=0.1).plot.hist(bins=50, ax=axes[0], color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0].set_title(\"Écart-type latitude par zip (clippé à 0.1)\")\n",
    "coord_variability[\"lng_std\"].clip(upper=0.1).plot.hist(bins=50, ax=axes[1], color=\"coral\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Écart-type longitude par zip (clippé à 0.1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabilité des noms de ville/état pour un même zip\n",
    "city_per_zip = geo.groupby(\"geolocation_zip_code_prefix\")[\"geolocation_city\"].nunique()\n",
    "state_per_zip = geo.groupby(\"geolocation_zip_code_prefix\")[\"geolocation_state\"].nunique()\n",
    "\n",
    "print(f\"Zips avec >1 nom de ville distinct : {(city_per_zip > 1).sum()}\")\n",
    "print(f\"Zips avec >1 état distinct         : {(state_per_zip > 1).sum()}\")\n",
    "print(\"\\n→ La variabilité des noms justifie l'utilisation du mode (valeur la plus fréquente)\")\n",
    "print(\"   plutôt que first() qui pourrait prendre une variante mal orthographiée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 customers — Grain et identité\n",
    "\n",
    "`customer_id` est unique par commande, `customer_unique_id` regroupe les achats d'un même client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = raw[\"customers\"]\n",
    "print(f\"customer_id uniques        : {cust['customer_id'].nunique():,}\")\n",
    "print(f\"customer_unique_id uniques : {cust['customer_unique_id'].nunique():,}\")\n",
    "\n",
    "ids_per_unique = cust.groupby(\"customer_unique_id\")[\"customer_id\"].nunique()\n",
    "print(f\"\\ncustomer_id par customer_unique_id — moy: {ids_per_unique.mean():.2f}, max: {ids_per_unique.max()}\")\n",
    "print(f\"Clients récurrents (>1 customer_id) : {(ids_per_unique > 1).sum():,} ({(ids_per_unique > 1).mean():.1%})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ids_per_unique.value_counts().sort_index().plot.bar(ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Distribution du nombre de customer_id par customer_unique_id\")\n",
    "ax.set_xlabel(\"Nombre de customer_id\")\n",
    "ax.set_ylabel(\"Nombre de customer_unique_id\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couverture zip → geolocation\n",
    "cust_zips = set(cust[\"customer_zip_code_prefix\"].dropna().astype(str))\n",
    "geo_zips = set(geo[\"geolocation_zip_code_prefix\"].dropna().astype(str))\n",
    "matched = cust_zips & geo_zips\n",
    "print(f\"Zips clients : {len(cust_zips):,}\")\n",
    "print(f\"Zips géoloc   : {len(geo_zips):,}\")\n",
    "print(f\"Zips matchés  : {len(matched):,} ({len(matched)/len(cust_zips):.1%})\")\n",
    "\n",
    "# Distribution géographique\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "cust[\"customer_state\"].value_counts().head(10).plot.barh(ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"Top 10 états (clients)\")\n",
    "axes[0].invert_yaxis()\n",
    "cust[\"customer_city\"].value_counts().head(15).plot.barh(ax=axes[1], color=\"coral\")\n",
    "axes[1].set_title(\"Top 15 villes (clients)\")\n",
    "axes[1].invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 sellers — Grain et géographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell = raw[\"sellers\"]\n",
    "print(f\"seller_id uniques : {sell['seller_id'].nunique():,}\")\n",
    "print(f\"Lignes totales    : {len(sell):,}\")\n",
    "print(f\"→ {'Unicité vérifiée ✓' if sell['seller_id'].nunique() == len(sell) else '⚠ Doublons détectés'}\")\n",
    "\n",
    "# Couverture zip → geolocation\n",
    "sell_zips = set(sell[\"seller_zip_code_prefix\"].dropna().astype(str))\n",
    "matched_s = sell_zips & geo_zips\n",
    "print(f\"\\nZips vendeurs matchés dans géoloc : {len(matched_s):,}/{len(sell_zips):,} ({len(matched_s)/len(sell_zips):.1%})\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sell[\"seller_state\"].value_counts().head(10).plot.barh(ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"Top 10 états (vendeurs)\")\n",
    "axes[0].invert_yaxis()\n",
    "sell[\"seller_city\"].value_counts().head(15).plot.barh(ax=axes[1], color=\"coral\")\n",
    "axes[1].set_title(\"Top 15 villes (vendeurs)\")\n",
    "axes[1].invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 orders — Temporalité et statuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_df = raw[\"orders\"].copy()\n",
    "\n",
    "# Distribution des statuts\n",
    "print(\"=== Statuts ===\")\n",
    "status_counts = ord_df[\"order_status\"].value_counts()\n",
    "print(status_counts.to_frame(\"count\").assign(pct=lambda x: (x[\"count\"] / x[\"count\"].sum() * 100).round(2)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "status_counts.plot.bar(ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Distribution des statuts de commande\")\n",
    "ax.set_ylabel(\"Nombre de commandes\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plage temporelle et volume mensuel\n",
    "ts_cols = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\",\n",
    "]\n",
    "for col in ts_cols:\n",
    "    ord_df[col] = pd.to_datetime(ord_df[col], errors=\"coerce\")\n",
    "\n",
    "print(\"=== Plage temporelle ===\")\n",
    "for col in ts_cols:\n",
    "    non_null = ord_df[col].dropna()\n",
    "    if len(non_null) > 0:\n",
    "        print(f\"  {col:45s} : {non_null.min().date()} → {non_null.max().date()} (null: {ord_df[col].isnull().sum():,})\")\n",
    "\n",
    "# Volume par mois\n",
    "monthly = ord_df.set_index(\"order_purchase_timestamp\").resample(\"ME\").size()\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "monthly.plot(ax=ax, marker=\"o\", color=\"steelblue\")\n",
    "ax.set_title(\"Volume de commandes par mois\")\n",
    "ax.set_ylabel(\"Nombre de commandes\")\n",
    "ax.set_xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps NULL — lien avec le statut\n",
    "print(\"=== Timestamps NULL par statut ===\")\n",
    "for col in ts_cols[1:]:\n",
    "    null_by_status = ord_df[ord_df[col].isnull()][\"order_status\"].value_counts()\n",
    "    if len(null_by_status) > 0:\n",
    "        print(f\"\\n{col} — NULL ({ord_df[col].isnull().sum():,} lignes) :\")\n",
    "        print(null_by_status.to_string())\n",
    "\n",
    "print(\"\\n→ delivered_customer_date est NULL pour les commandes non livrées (shipped, canceled, etc.)\")\n",
    "print(\"  C'est cohérent : pas de date de livraison si la commande n'est pas arrivée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 order_items — Grain article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = raw[\"order_items\"]\n",
    "\n",
    "# Items par commande\n",
    "items_per = items.groupby(\"order_id\").size()\n",
    "print(f\"Items par commande — moy: {items_per.mean():.2f}, médiane: {items_per.median():.0f}, max: {items_per.max()}\")\n",
    "print(f\"Commandes mono-item : {(items_per == 1).sum():,} ({(items_per == 1).mean():.1%})\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "items_per.clip(upper=10).plot.hist(bins=range(1, 12), ax=axes[0], color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0].set_title(\"Items par commande (clippé à 10)\")\n",
    "axes[0].set_xlabel(\"Nombre d'items\")\n",
    "\n",
    "items[\"price\"].plot.hist(bins=50, ax=axes[1], color=\"coral\", edgecolor=\"white\", log=True)\n",
    "axes[1].set_title(\"Distribution des prix (échelle log)\")\n",
    "axes[1].set_xlabel(\"Prix (BRL)\")\n",
    "\n",
    "items[\"freight_value\"].plot.hist(bins=50, ax=axes[2], color=\"mediumseagreen\", edgecolor=\"white\", log=True)\n",
    "axes[2].set_title(\"Distribution des frais de livraison (échelle log)\")\n",
    "axes[2].set_xlabel(\"Freight (BRL)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers prix et freight\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "items[[\"price\"]].plot.box(ax=axes[0], vert=True)\n",
    "axes[0].set_title(\"Boxplot des prix\")\n",
    "items[[\"freight_value\"]].plot.box(ax=axes[1], vert=True)\n",
    "axes[1].set_title(\"Boxplot des frais de livraison\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Prix — min: {items['price'].min():.2f}, max: {items['price'].max():.2f}\")\n",
    "print(f\"Freight — min: {items['freight_value'].min():.2f}, max: {items['freight_value'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification FK order_items → products et sellers\n",
    "orphan_products = items[~items[\"product_id\"].isin(products[\"product_id\"])]\n",
    "orphan_sellers = items[~items[\"seller_id\"].isin(sellers[\"seller_id\"])]\n",
    "print(f\"Items sans produit correspondant : {len(orphan_products)}\")\n",
    "print(f\"Items sans vendeur correspondant : {len(orphan_sellers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 order_payments — Paiements multiples\n",
    "\n",
    "Une commande peut avoir plusieurs lignes de paiement (carte + voucher, etc.).\n",
    "→ Justifie l'agrégation `sum(payment_value)` + `mode(payment_type)` par commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pays = raw[\"order_payments\"]\n",
    "\n",
    "pays_per = pays.groupby(\"order_id\").size()\n",
    "print(f\"Paiements par commande — moy: {pays_per.mean():.2f}, max: {pays_per.max()}\")\n",
    "print(f\"Commandes mono-paiement : {(pays_per == 1).sum():,} ({(pays_per == 1).mean():.1%})\")\n",
    "\n",
    "# Commandes mixant plusieurs types de paiement\n",
    "types_per_order = pays.groupby(\"order_id\")[\"payment_type\"].nunique()\n",
    "multi_type = (types_per_order > 1).sum()\n",
    "print(f\"Commandes avec >1 type de paiement : {multi_type:,} ({multi_type/len(types_per_order):.1%})\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "pays[\"payment_type\"].value_counts().plot.bar(ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"Répartition par type de paiement\")\n",
    "axes[0].set_ylabel(\"Nombre de lignes\")\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "pays[\"payment_value\"].clip(upper=1000).plot.hist(bins=50, ax=axes[1], color=\"coral\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Distribution payment_value (clippé à 1000 BRL)\")\n",
    "axes[1].set_xlabel(\"Payment value (BRL)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détail des paiements à valeur 0\n",
    "zero_pays = pays[pays[\"payment_value\"] == 0]\n",
    "print(f\"Paiements à valeur 0 : {len(zero_pays):,}\")\n",
    "if len(zero_pays) > 0:\n",
    "    print(zero_pays[\"payment_type\"].value_counts())\n",
    "\n",
    "print(\"\\n→ Les paiements multiples et les types mixtes justifient l'agrégation\")\n",
    "print(\"  sum(payment_value) + mode(payment_type) par commande dans fact_orders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 order_reviews — Reviews multiples\n",
    "\n",
    "La plupart des commandes ont 1 review, mais certaines en ont plusieurs.\n",
    "→ Justifie le choix de garder la review la plus récente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = raw[\"order_reviews\"]\n",
    "\n",
    "revs_per = revs.groupby(\"order_id\").size()\n",
    "multi_rev = (revs_per > 1).sum()\n",
    "print(f\"Reviews par commande — moy: {revs_per.mean():.2f}, max: {revs_per.max()}\")\n",
    "print(f\"Commandes avec >1 review : {multi_rev} ({multi_rev/len(revs_per):.2%})\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "revs[\"review_score\"].value_counts().sort_index().plot.bar(ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"Distribution des review_score\")\n",
    "axes[0].set_xlabel(\"Score\")\n",
    "axes[0].set_ylabel(\"Nombre de reviews\")\n",
    "\n",
    "# Taux de commentaires vides\n",
    "comment_empty = revs[\"review_comment_message\"].isnull().mean()\n",
    "title_empty = revs[\"review_comment_title\"].isnull().mean()\n",
    "pd.Series({\"comment_message vide\": comment_empty, \"comment_title vide\": title_empty}).plot.bar(\n",
    "    ax=axes[1], color=[\"coral\", \"salmon\"]\n",
    ")\n",
    "axes[1].set_title(\"Taux de champs texte vides\")\n",
    "axes[1].set_ylabel(\"Proportion\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCommentaires vides : {comment_empty:.1%}\")\n",
    "print(f\"Titres vides       : {title_empty:.1%}\")\n",
    "print(f\"\\n→ Les textes sont souvent vides. Seul review_score est retenu dans fact_orders.\")\n",
    "print(f\"  Les {multi_rev} commandes multi-reviews justifient le choix de la review la plus récente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 products + category_translation\n",
    "\n",
    "Fusion de deux CSV : `products` contient les catégories en portugais,\n",
    "`category_translation` fournit la traduction anglaise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = raw[\"products\"]\n",
    "cat_tr = raw[\"category_translation\"]\n",
    "\n",
    "# Valeurs manquantes dans products\n",
    "print(\"=== Valeurs manquantes dans products ===\")\n",
    "missing_prods = prods.isnull().sum()\n",
    "missing_prods = missing_prods[missing_prods > 0]\n",
    "print(missing_prods.to_frame(\"null_count\").assign(pct=lambda x: (x[\"null_count\"] / len(prods) * 100).round(2)))\n",
    "\n",
    "# Couverture de la traduction\n",
    "cats_pt = set(prods[\"product_category_name\"].dropna().unique())\n",
    "cats_translated = set(cat_tr[\"product_category_name\"].unique())\n",
    "not_translated = cats_pt - cats_translated\n",
    "print(f\"\\n=== Couverture traduction ===\")\n",
    "print(f\"Catégories PT dans products  : {len(cats_pt)}\")\n",
    "print(f\"Catégories dans translation  : {len(cats_translated)}\")\n",
    "print(f\"Catégories non traduites     : {len(not_translated)}\")\n",
    "if not_translated:\n",
    "    print(f\"  → {not_translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 catégories\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "prods[\"product_category_name\"].value_counts().head(20).plot.barh(ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Top 20 catégories de produits\")\n",
    "ax.set_xlabel(\"Nombre de produits\")\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributs physiques : outliers et nulls\n",
    "phys_cols = [\"product_weight_g\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"]\n",
    "\n",
    "print(\"=== Statistiques des attributs physiques ===\")\n",
    "display(prods[phys_cols].describe().round(1))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for ax, col in zip(axes, phys_cols):\n",
    "    prods[col].dropna().plot.box(ax=ax)\n",
    "    ax.set_title(col.replace(\"product_\", \"\"))\n",
    "plt.suptitle(\"Boxplots des attributs physiques\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes product_name_lenght / product_description_lenght\n",
    "print(\"=== product_name_lenght & product_description_lenght ===\")\n",
    "for col in [\"product_name_lenght\", \"product_description_lenght\"]:\n",
    "    if col in prods.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  null: {prods[col].isnull().sum()}, moy: {prods[col].mean():.0f}, max: {prods[col].max():.0f}\")\n",
    "\n",
    "print(\"\\n→ Ce sont des métadonnées dérivées (longueur en caractères du nom/description).\")\n",
    "print(\"  Elles n'apportent pas de valeur analytique directe → exclues de dim_products.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet_3_Olist (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
