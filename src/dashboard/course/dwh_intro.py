"""
Introduction dÃ©taillÃ©e du Data Warehouse Olist.

6 slides :
1. Contexte Olist (dataset, volumÃ©trie exacte)
2. Processus ETL (5 transformations clÃ©s avec justifications empiriques)
3. SchÃ©ma en Ã©toile (cardinalitÃ©s exactes, grain article explicitÃ©)
4. DÃ©cisions architecturales (vues VIRTUELLES, pas matÃ©rialisÃ©es)
5. Validation & QualitÃ© (concordance 100%, anomalies documentÃ©es)
6. Valeur business (9 mÃ©triques rÃ©elles, limites assumÃ©es, transition cours)
"""

from nicegui import ui


def render_intro_carousel():
    """Affiche l'introduction DWH avec navigation manuelle entre slides."""

    # Ã‰tat de navigation
    current_slide = {'index': 0}
    total_slides = 6

    # Container principal
    slide_container = ui.column().classes('w-full')

    def render_slide(index: int):
        """Affiche le slide Ã  l'index donnÃ©."""
        slide_container.clear()

        with slide_container:
            # Progress indicator
            with ui.row().classes('w-full justify-center mb-4'):
                for i in range(total_slides):
                    if i == index:
                        ui.label('â—').classes('text-green-400 text-2xl')
                    else:
                        ui.label('â—‹').classes('text-gray-600 text-2xl')

            # Contenu du slide
            with ui.card().classes('w-full p-8 chapter-enter'):
                if index == 0:
                    render_slide_1()
                elif index == 1:
                    render_slide_2()
                elif index == 2:
                    render_slide_3()
                elif index == 3:
                    render_slide_4()
                elif index == 4:
                    render_slide_5()
                elif index == 5:
                    render_slide_6()

            # Navigation
            with ui.row().classes('w-full justify-between mt-4'):
                if index > 0:
                    ui.button('â† PrÃ©cÃ©dent', on_click=lambda: navigate(-1)).props('outline')
                else:
                    ui.label('')  # Spacer

                if index < total_slides - 1:
                    ui.button('Suivant â†’', on_click=lambda: navigate(1)).props('color=primary')
                else:
                    ui.button('Commencer le cours ğŸš€', on_click=start_course).props('color=positive')

    def navigate(delta: int):
        """Navigue entre les slides."""
        current_slide['index'] = max(0, min(total_slides - 1, current_slide['index'] + delta))
        render_slide(current_slide['index'])

    def start_course():
        """Redirige vers la premiÃ¨re leÃ§on."""
        ui.navigate.to('/presentation/module_1_fundamentals/0')

    # Afficher premier slide
    render_slide(0)


def render_slide_1():
    """Slide 1 : Contexte Olist."""
    ui.label("ğŸ¯ Le Dataset Olist").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Dataset E-commerce BrÃ©silien (2016-2018)

**Olist** est une plateforme e-commerce brÃ©silienne qui connecte des milliers de vendeurs indÃ©pendants avec les plus grandes marketplaces du pays.

### Les chiffres clÃ©s
- ğŸ›’ **99 441 commandes** sur 24 mois (septembre 2016 - octobre 2018)
- ğŸ‘¥ **96 096 clients** uniques (`customer_unique_id`)
- ğŸª **3 095 vendeurs** actifs
- ğŸ“¦ **32 951 produits** diffÃ©rents
- ğŸ“ **19 015 codes postaux** uniques (couvrant 27 Ã©tats brÃ©siliens)
- ğŸŒ **27 Ã©tats** brÃ©siliens couverts

### VolumÃ©trie totale des donnÃ©es sources
**1 550 871 lignes brutes** rÃ©parties dans **9 fichiers CSV**, dont :
- 77% (1M lignes) = geolocation Ã  dÃ©dupliquer
- 23% = donnÃ©es transactionnelles et rÃ©fÃ©rentielles

### Les 9 fichiers CSV sources
1. `olist_orders_dataset.csv` (99 441 lignes)
2. `olist_order_items_dataset.csv` (112 650 lignes)
3. `olist_customers_dataset.csv` (99 441 lignes)
4. `olist_sellers_dataset.csv` (3 095 lignes)
5. `olist_products_dataset.csv` (32 951 lignes)
6. `olist_order_reviews_dataset.csv` (99 224 lignes)
7. `olist_order_payments_dataset.csv` (103 886 lignes)
8. `olist_geolocation_dataset.csv` (1 000 163 lignes!)
9. `product_category_name_translation.csv` (71 lignes)

â¡ï¸ **Objectif** : Construire un Data Warehouse analytique optimisÃ©
""").classes('text-gray-300')


def render_slide_2():
    """Slide 2 : Processus ETL."""
    ui.label("âš™ï¸ Le Processus ETL").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Extract â†’ Transform â†’ Load

Notre pipeline de transformation suit les Ã©tapes classiques de l'ingÃ©nierie des donnÃ©es.
""").classes('text-gray-300 mb-4')

    # SchÃ©ma Mermaid du flow ETL
    ui.mermaid("""
graph LR
    A[9 CSV Sources<br/>1 550 871 lignes] -->|Extract| B[DataFrames Pandas]
    B -->|Transform| C[Cleaning + Engineering]
    C -->|Load| D[(SQLite DWH<br/>6 tables)]

    style A fill:#e74c3c
    style B fill:#f39c12
    style C fill:#3498db
    style D fill:#27ae60

    C -->|clean_geolocation| C1[DÃ©dup 1M â†’ 19K]
    C -->|aggregate_payments| C2[SUM + MODE par order]
    C -->|latest_review| C3[Garder plus rÃ©cent]
    C -->|surrogate_keys| C4[UUID â†’ INTEGER]
    C -->|delivery_metrics| C5[Calculs temporels]
""").classes('w-full mb-4')

    ui.markdown("""
### 1. **Extract** : Chargement des CSV
```python
orders_df = pd.read_csv("olist_orders_dataset.csv")      # 99 441 lignes
items_df = pd.read_csv("olist_order_items_dataset.csv")  # 112 650 lignes
# ... 7 autres CSV
```

### 2. **Transform** : 5 transformations clÃ©s

#### ğŸ”¸ **`clean_geolocation`** : DÃ©doublonner codes postaux
- **Pourquoi** : 1M lignes pour 19K codes postaux uniques (53 entrÃ©es/zip en moyenne)
- **MÃ©thode** : MÃ©diane lat/lng par zip_code_prefix (robuste aux outliers)
- **RÃ©sultat** : 1 000 163 â†’ 19 015 lignes, prÃ©cision ~2km

```python
def _safe_mode(x):
    \"\"\"Mode sÃ©curisÃ© Ã©vitant IndexError sur sÃ©ries vides.\"\"\"
    mode = x.mode()
    return mode.iloc[0] if not mode.empty else (x.iloc[0] if len(x) > 0 else None)

def clean_geolocation(df):
    return df.groupby('zip_code_prefix', as_index=False).agg({
        'lat': 'median',
        'lng': 'median',
        'city': _safe_mode,
        'state': _safe_mode
    })
```

#### ğŸ”¸ **`aggregate_payments`** : Fusionner paiements multiples
- **Pourquoi** : 103 886 lignes pour 99 441 commandes (97% mono-paiement)
- **MÃ©thode** : SUM(payment_value), MODE(payment_type) par order_id
- **RÃ©sultat** : order_payment_total = montant total, payment_type = type dominant

#### ğŸ”¸ **`latest_review_per_order`** : RÃ©soudre reviews multiples
- **Pourquoi** : 547 commandes ont plusieurs reviews (0.5%)
- **MÃ©thode** : Garder la review la plus rÃ©cente (MAX(review_creation_date))
- **RÃ©sultat** : 1 review par commande (99 224 â†’ 98 666 commandes avec review)

#### ğŸ”¸ **`create_surrogate_keys`** : Optimiser clÃ©s Ã©trangÃ¨res
- **Pourquoi** : UUID 32 char (32 bytes) â†’ INTEGER (4 bytes) = 8Ã— moins d'espace
- **MÃ©thode** : AUTOINCREMENT sur customer_key, seller_key, product_key
- **RÃ©sultat** : Jointures 8Ã— plus rapides, index B-Tree optimaux

#### ğŸ”¸ **`calculate_delivery_metrics`** : Feature engineering temporel
- **MÃ©thodes** :
  - `delivery_days` = delivered_date - purchase_date
  - `estimated_days` = estimated_delivery_date - purchase_date
  - `delivery_delta_days` = delivery_days - estimated_days (positif = retard)
- **RÃ©sultat** : MÃ©triques prÃ©calculÃ©es pour analyses logistiques

### 3. **Load** : Insertion dans SQLite avec 5 index stratÃ©giques

```python
# SchÃ©ma en Ã©toile : 1 fait + 5 dimensions
fact_orders.to_sql('fact_orders', conn, index=False)
dim_customers.to_sql('dim_customers', conn, index=False)
# ... 4 autres dimensions

# Index critiques (accÃ©lÃ©ration 100Ã—)
conn.execute("CREATE INDEX idx_orders_date ON fact_orders(date_key)")
conn.execute("CREATE INDEX idx_orders_customer ON fact_orders(customer_key)")
conn.execute("CREATE INDEX idx_orders_seller ON fact_orders(seller_key)")
conn.execute("CREATE INDEX idx_orders_product ON fact_orders(product_key)")
conn.execute("CREATE INDEX idx_orders_status ON fact_orders(order_status)")
```

â¡ï¸ **RÃ©sultat** : 1.5M lignes brutes â†’ 287K lignes structurÃ©es, queryable en <200ms
""").classes('text-gray-300')


def render_slide_3():
    """Slide 3 : SchÃ©ma en Ã©toile."""
    ui.label("â­ SchÃ©ma en Ã‰toile").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## ModÃ©lisation dimensionnelle : Le cÅ“ur du DWH

Le schÃ©ma en Ã©toile est le standard pour les Data Warehouses analytiques.
""").classes('text-gray-300 mb-4')

    # SchÃ©ma ERD avec Mermaid
    ui.mermaid("""
erDiagram
    fact_orders ||--o{ dim_customers : "customer_key"
    fact_orders ||--o{ dim_sellers : "seller_key"
    fact_orders ||--o{ dim_products : "product_key"
    fact_orders ||--o{ dim_geolocation : "customer_zip_code"
    fact_orders ||--o{ dim_dates : "order_date"

    fact_orders {
        int order_item_id PK
        string order_id
        int customer_key FK
        int seller_key FK
        int product_key FK
        date order_date
        decimal price
        string order_status
        int delivery_days
        int review_score
    }

    dim_customers {
        int customer_key PK
        string customer_id
        string customer_city
        string customer_state
    }

    dim_sellers {
        int seller_key PK
        string seller_id
        string seller_city
        string seller_state
    }

    dim_products {
        int product_key PK
        string product_id
        string category
        decimal weight_g
        decimal volume_cm3
    }

    dim_geolocation {
        string zip_code PK
        string city
        string state
        float lat
        float lng
    }

    dim_dates {
        date date_key PK
        int year
        int month
        int day
        int week
        string month_name
    }
""").classes('w-full mb-4')

    ui.markdown("""
### ğŸ“Š CardinalitÃ©s

| Table | Lignes | RÃ´le |
|-------|--------|------|
| **fact_orders** | 112 650 | **Table de faits** (transactions) |
| dim_customers | 96 096 | Attributs clients (ville, Ã©tat) |
| dim_sellers | 3 095 | Attributs vendeurs |
| dim_products | 32 951 | CatÃ©gories, dimensions produits |
| dim_geolocation | 19 015 | Codes postaux dÃ©doublonnÃ©s |
| dim_dates | 715 | Calendrier (2016-09-04 â†’ 2018-11-12) |

### ğŸ”‘ Grain de la table de faits
**1 ligne = 1 article d'une commande** (order_id + order_item_id)

**Distribution grain commande â†’ article** :
- **90.1% des commandes** = 1 seul article (mono-item)
- **9.9% des commandes** = 2 Ã  21 articles (multi-items)
- **Total** : 99 441 commandes â†’ 112 650 lignes (ratio 1.13)

**Exemple** : Commande #abc123 avec 3 articles â†’ 3 lignes dans fact_orders (order_item_id = 1, 2, 3)

**Pourquoi ce grain ?**
- âœ… Permet d'agrÃ©ger au niveau commande (`GROUP BY order_id`) ou article
- âœ… Conserve le dÃ©tail maximal (prix unitaire par article, vendeur par article)
- âœ… Facilite les analyses produit (quel article gÃ©nÃ¨re le plus de CA ?)

**âš ï¸ Attention aux mÃ©triques semi-additives** :
- `order_payment_total` est au grain **commande**, pas article
- Exemple : Commande 100 R$ avec 2 articles â†’ chaque ligne affiche 100 R$
- **Pour obtenir le total correct** : `SELECT DISTINCT order_id, order_payment_total` puis SUM

### ğŸ¯ Avantages du schÃ©ma en Ã©toile
- âœ… **Jointures simples** : 1 saut de la fact vers chaque dimension
- âœ… **Performance** : ClÃ©s surrogate (int) ultra-rapides (8Ã— moins d'espace que UUID)
- âœ… **LisibilitÃ©** : Structure intuitive (centre + branches)
- âœ… **FlexibilitÃ©** : Ajouter une dimension = 1 colonne FK dans fact
""").classes('text-gray-300')


def render_slide_4():
    """Slide 4 : DÃ©cisions architecturales."""
    ui.label("ğŸ—ï¸ DÃ©cisions Architecturales").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Choix techniques qui rendent le DWH performant

### 1. **Grain : Article vs Commande**

**Option 1 - Grain "Commande"** (rejetÃ©) :
- âŒ Perd le dÃ©tail par article
- âŒ Prix agrÃ©gÃ©s (impossible de savoir quel produit coÃ»te combien)
- âŒ Reviews moyennÃ©es (perd la granularitÃ©)

**Option 2 - Grain "Article"** (âœ… choisi) :
- âœ… DÃ©tail maximal conservÃ©
- âœ… AgrÃ©ger au niveau commande reste possible (`GROUP BY order_id`)
- âœ… Analyses produit facilitÃ©es

â¡ï¸ **DÃ©cision** : 1 ligne = 1 article (112k lignes dans fact_orders)

---

### 2. **Index StratÃ©giques**

Les index accÃ©lÃ¨rent les recherches de O(n) â†’ O(log n).

**Index crÃ©Ã©s** :
```sql
CREATE INDEX idx_orders_date ON fact_orders(order_date);
CREATE INDEX idx_orders_status ON fact_orders(order_status);
CREATE INDEX idx_orders_customer ON fact_orders(customer_key);
CREATE INDEX idx_orders_seller ON fact_orders(seller_key);
CREATE INDEX idx_orders_product ON fact_orders(product_key);
```

**Impact** :
- Filtrage WHERE sur `order_date` : **100x plus rapide** (0.5ms vs 50ms)
- Jointures fact â†’ dimensions : **InstantanÃ©es** (dÃ©jÃ  indexÃ©es)
- Tri ORDER BY : **OptimisÃ©** (index covering)

**Principe** : Indexer toutes les clÃ©s Ã©trangÃ¨res + colonnes filtrÃ©es frÃ©quemment.

---

### 3. **Vues Analytiques (virtuelles, pas matÃ©rialisÃ©es)**

âš ï¸ **SQLite ne supporte PAS les vues matÃ©rialisÃ©es** (contrairement Ã  PostgreSQL)

Les vues crÃ©Ã©es sont **virtuelles** : recalculÃ©es Ã  chaque SELECT, pas de cache physique.

**3 vues crÃ©Ã©es** :

#### ğŸ“Š `v_monthly_sales` : Ventes mensuelles agrÃ©gÃ©es
```sql
CREATE VIEW v_monthly_sales AS
SELECT
    d.year,
    d.month,
    d.year || '-' || PRINTF('%02d', d.month) AS month_label,
    ROUND(SUM(f.price), 2) AS monthly_revenue,
    COUNT(DISTINCT f.order_id) AS monthly_orders,
    ROUND(SUM(f.price) * 1.0 / NULLIF(COUNT(DISTINCT f.order_id), 0), 2) AS avg_basket
FROM fact_orders f
JOIN dim_dates d ON f.date_key = d.date_key
WHERE f.order_status = 'delivered'
GROUP BY d.year, d.month;
```

#### ğŸ‘¥ `v_customer_cohorts` : Clients avec mois de premiÃ¨re commande
```sql
CREATE VIEW v_customer_cohorts AS
SELECT
    c.customer_unique_id,
    MIN(f.date_key / 100) AS first_month,
    (MIN(f.date_key / 100) / 100) || '-' || PRINTF('%02d', MIN(f.date_key / 100) % 100) AS first_month_label,
    COUNT(DISTINCT f.order_id) AS total_orders,
    ROUND(SUM(f.price), 2) AS total_spent
FROM fact_orders f
JOIN dim_customers c ON f.customer_key = c.customer_key
WHERE f.order_status = 'delivered'
  AND f.date_key IS NOT NULL
GROUP BY c.customer_unique_id;
```

#### ğŸ“¦ `v_orders_enriched` : Commandes avec toutes dimensions joinÃ©es
Vue dÃ©normalisÃ©e pour analyses ad-hoc sans rÃ©Ã©crire les JOINs.

**Avantage** : RequÃªtes complexes deviennent `SELECT * FROM v_monthly_sales`.

**Limite** : Pas de cache. Pour matÃ©rialiser : `CREATE TABLE AS SELECT ...` (manuelle).

---

### 4. **ClÃ©s Surrogate vs ClÃ©s Naturelles**

**ClÃ© naturelle** : `customer_id` (string UUID 32 chars, 32 bytes)

**ClÃ© surrogate** : `customer_key` (integer auto-incrÃ©mentÃ©, 4 bytes)

**Impact** :
- âœ… **8x moins d'espace** (4 bytes vs 32)
- âœ… **Jointures plus rapides** (Ã©galitÃ© sur int vs string)
- âœ… **Index plus compacts** (B-Tree sur int = optimal)

â¡ï¸ **DÃ©cision** : Toutes les FK utilisent des clÃ©s surrogate (customer_key, seller_key, product_key).

---

### 5. **SQLite vs PostgreSQL**

Pourquoi SQLite pour un DWH ?

**Avantages** :
- âœ… **Zero-config** : 1 fichier .db, pas de serveur
- âœ… **Portable** : Copier le .db = copier tout le DWH
- âœ… **Rapide** : Window functions performantes, optimiseur correct
- âœ… **Suffisant** : < 1M lignes = parfait pour SQLite

**Limites** (OK pour notre use case) :
- âŒ Pas de concurrence Ã©criture (read-only en prod = OK)
- âŒ Pas de rÃ©plication (backup fichier = OK)
- âŒ Pas de partitionnement (pas nÃ©cessaire Ã  112k lignes)

â¡ï¸ **DÃ©cision** : SQLite est idÃ©al pour un DWH analytique mono-utilisateur.
""").classes('text-gray-300')


def render_slide_5():
    """Slide 5 : Validation & QualitÃ© des DonnÃ©es."""
    ui.label("âœ… Validation & QualitÃ© des DonnÃ©es").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## IntÃ©gritÃ© des transformations CSV â†’ DWH

La validation systÃ©matique garantit que les transformations ETL n'ont introduit aucune perte de donnÃ©es ni erreur de calcul.

---

### ğŸ“Š Tableau de concordance CSV â†” DWH

| EntitÃ© | CSV Source | Data Warehouse | Match | Observations |
|--------|-----------|----------------|-------|--------------|
| **Customers** | 99 441 | 99 441 | **100% âœ…** | customer_id concordent, villes normalisÃ©es (Title Case) |
| **Products** | 32 951 | 32 951 | **100% âœ…** | product_id identiques, traduction EN ajoutÃ©e via jointure |
| **Sellers** | 3 095 | 3 095 | **100% âœ…** | seller_id identiques |
| **Order Items** | 112 650 | 112 650 | **100% âœ…** | Nombre de lignes strictement identique (grain article) |
| **Prix total** | 13 591 643.70 R$ | 13 591 643.70 R$ | **100% âœ…** | Somme totale des prix strictement identique |
| **Fret total** | 2 251 909.54 R$ | 2 251 909.54 R$ | **100% âœ…** | Somme totale du fret strictement identique |
| **Paiements** | 103 886 lignes | AgrÃ©gÃ© par order | **100% âœ…** | 100% des totaux par commande concordent |

**Verdict global** : **0 perte financiÃ¨re**, intÃ©gritÃ© 100% sur les entitÃ©s et montants.

---

### ğŸš¨ Anomalies identifiÃ©es et documentÃ©es

#### 1. **775 commandes sans articles (0.78%)**
- **Statuts** : unavailable (603), canceled (164), created (5), invoiced (2), shipped (1)
- **Traitement** : Exclus de fact_orders car grain = article (cohÃ©rent avec modÃ©lisation)
- **Impact** : Aucun sur analyses produit/vendeur (commandes sans transaction)

#### 2. **285 entitÃ©s sans geolocation**
- **DÃ©tail** : 278 clients (0.28%) + 7 vendeurs (0.23%)
- **Cause** : Codes postaux absents de `olist_geolocation_dataset.csv`
- **Traitement** : geo_key = NULL dans dim_customers/dim_sellers
- **Impact** : Analyses gÃ©ographiques possibles, entitÃ©s NULL filtrables

#### 3. **PrÃ©cision gÃ©olocalisation ~2 km**
- **MÃ©thode** : MÃ©diane lat/lng par code postal (1M â†’ 19K lignes)
- **Ã‰cart mÃ©dian** : 0.02Â° lat, 0.018Â° lng â‰ˆ 2 km
- **QualitÃ©** : OK pour analyses rÃ©gionales/Ã©tats, insuffisant pour gÃ©ocodage prÃ©cis

#### 4. **942 commandes sans review (0.95%)**
- **Cause** : Commandes non livrÃ©es ou reviews non soumises
- **Traitement** : review_score = NULL dans fact_orders
- **Impact** : Exclus des calculs avg_review (fonction AVG ignore NULL)

---

### ğŸ§ª Script de validation indÃ©pendant

**`verify_csv_analysis.sh`** : 50+ assertions automatisÃ©es

```bash
#!/bin/bash
# Validation continue aprÃ¨s chaque modification ETL

# Exemple d'assertions
assert_count "orders CSV" 99441 "wc -l < data/raw/olist_orders_dataset.csv"
assert_count "fact_orders DB" 112650 "sqlite3 olist_dw.db 'SELECT COUNT(*) FROM fact_orders'"
assert_sum "prix CSV" 13591643.70 "csvstat --sum price olist_order_items_dataset.csv"
assert_sum "prix DB" 13591643.70 "sqlite3 olist_dw.db 'SELECT SUM(price) FROM fact_orders'"

# ... 46 autres assertions
```

**Avantage** : Reproduit tous les chiffres clÃ©s via csvkit + SQLite temporaire â†’ validation reproductible.

---

### ğŸ¯ Distribution des valeurs NULL dans fact_orders

| Colonne | NULLs | % | Explication |
|---------|-------|---|-------------|
| `delivery_days` | 2 454 | 2.2% | Commandes non livrÃ©es (shipped, canceled) |
| `review_score` | 942 | 0.8% | Commandes sans avis client |
| `customer_geo_key` | 302 | 0.3% | Codes postaux clients absents de dim_geolocation |
| `seller_geo_key` | 253 | 0.2% | Codes postaux vendeurs absents de dim_geolocation |
| `order_payment_total` | 3 | 0.003% | Anomalie marginale (potentielle erreur source) |

**Traitement** : Valeurs NULL conservÃ©es (pas d'imputation arbitraire), filtrables via `WHERE column IS NOT NULL`.

---

## âœ… Conclusion : QualitÃ© validÃ©e

- âœ… **IntÃ©gritÃ© 100%** sur entitÃ©s, montants financiers et volumes
- âœ… **0 perte de donnÃ©es** sur transactions valides (grain article)
- âœ… **Anomalies documentÃ©es** (775 commandes sans articles = exclusion cohÃ©rente)
- âœ… **Validation continue** via script indÃ©pendant (50+ assertions automatisÃ©es)

â¡ï¸ Le DWH est fiable pour analyses mÃ©tier et dÃ©cisions stratÃ©giques
""").classes('text-gray-300')


def render_slide_6():
    """Slide 6 : Justification business."""
    ui.label("ğŸ’¼ Valeur Business du DWH").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Pourquoi investir dans un Data Warehouse ?

### ğŸ¯ Dimensions mÃ©tier activÃ©es

Le DWH Olist permet d'analyser le business sous **5 dimensions** :

1. **ğŸ“… Temps** : Tendances mensuelles, saisonnalitÃ©, cohortes
2. **ğŸŒ GÃ©ographie** : Performance par Ã©tat/ville (client ET vendeur)
3. **ğŸ‘¥ Clients** : Segmentation RFM, LTV, rÃ©tention, nouveaux vs rÃ©currents
4. **ğŸª Vendeurs** : Scoring multi-critÃ¨res, Pareto, qualitÃ© livraison
5. **ğŸ“¦ Produits** : CatÃ©gories star, panier moyen, cross-sell

**Impossible avec CSV bruts** : Chaque dimension nÃ©cessite des jointures complexes et des agrÃ©gations.

---

### ğŸ“Š 9 MÃ©triques mÃ©tier dÃ©bloquÃ©es par le DWH

| MÃ©trique | Description | RequÃªte SQL |
|----------|-------------|-------------|
| **Taux de rÃ©tention par cohorte** | % clients revenus M+1, M+2... aprÃ¨s 1er achat | `cohorts_retention.sql` |
| **LTV (Lifetime Value)** | CA total par client unique | `ltv_cohorts.sql` |
| **Nouveaux vs rÃ©currents** | Nombre clients 1er achat vs dÃ©jÃ  actifs par mois | `new_vs_recurring.sql` |
| **Pareto vendeurs** | Top 20% vendeurs gÃ©nÃ¨rent X% du CA | `pareto_sellers.sql` |
| **Panier moyen** | CA / nb commandes | `basket_avg.sql` |
| **Score review moyen** | Moyenne des avis clients (1-5 Ã©toiles) | `overview_kpis.sql` |
| **Segmentation RFM** | Recency, Frequency, Monetary (10 segments) | `rfm_segmentation.sql` |
| **Scoring vendeurs** | Note multi-critÃ¨res (dÃ©lai, review, CA) | `seller_scoring.sql` |
| **DÃ©lai livraison moyen** | Jours entre achat et livraison effective | `overview_kpis.sql` |

**ROI direct** : Ces KPIs pilotent les dÃ©cisions stratÃ©giques (oÃ¹ investir, quels produits pousser, quels vendeurs coacher).

---

### âš¡ RapiditÃ© = AgilitÃ© dÃ©cisionnelle

**Avant (CSV)** :
- Analyste : 30 min de code Python â†’ attendre 5s â†’ debugger â†’ rÃ©exÃ©cuter...
- Total : **2-3h** pour une analyse ad-hoc
- RÃ©sultat : **1 analyse par jour** max

**AprÃ¨s (DWH)** :
- Analyste : 5 min de SQL â†’ rÃ©sultat en 0.2s â†’ itÃ©rer rapidement
- Total : **10-15 min** pour une analyse ad-hoc
- RÃ©sultat : **10-20 analyses par jour**

â¡ï¸ **10x plus de questions business rÃ©pondues** = dÃ©cisions data-driven plus rapides.

---

### ğŸ” ComplexitÃ©s impossibles sans DWH

Certaines analyses sont **impossibles** (ou prohibitives) avec CSV Pandas :

#### 1. **Auto-jointures temporelles**
"Clients ayant commandÃ© X puis Y dans les 30 jours suivants" â†’ Self-join sur dates.

#### 2. **Window functions complexes**
"Rang du produit par catÃ©gorie ET par Ã©tat" â†’ PARTITION BY multi-niveaux.

#### 3. **CTEs rÃ©cursives**
"Parcours clients sur N commandes" â†’ WITH RECURSIVE (pas supportÃ© en Pandas).

#### 4. **Sous-requÃªtes corrÃ©lÃ©es optimisÃ©es**
"Top 3 produits par vendeur" â†’ CTE + ROW_NUMBER (vs boucles Pandas).

---

### ğŸ’° Ã‰conomies estimÃ©es (ordres de grandeur)

**Infrastructure** :
- âŒ CSV : Serveur 32GB RAM pour charger donnÃ©es en mÃ©moire
- âœ… DWH : SQLite = 1 fichier 50MB, serveur 2GB RAM
- **Gain estimÃ©** : **10Ã— moins cher** en infrastructure cloud

**Temps analyste** :
- âŒ CSV : Analyses lentes (5-10s), code complexe (150+ lignes)
- âœ… DWH : Analyses rapides (0.2-0.5s), requÃªtes concises (80 lignes SQL)
- **Gain estimÃ©** : **15-25h/semaine libÃ©rÃ©es** pour analyses avancÃ©es

**âš ï¸ Note** : Chiffres indicatifs, varient selon organisation, volumÃ©trie et infrastructure existante.

---

### ğŸš€ Ã‰volutivitÃ©

Le DWH est **futur-proof** :
- âœ… Ajouter une nouvelle dimension (ex: `dim_categories`) = 1 colonne FK dans fact
- âœ… Ajouter une nouvelle mÃ©trique = 1 nouvelle colonne calculÃ©e
- âœ… Migrer vers PostgreSQL si croissance > 10M lignes = schema compatible

**Pandas CSV n'est PAS Ã©volutif** : Chaque nouvelle source = refactor complet du pipeline.

---

## âœ… Conclusion : DWH = Fondation analytique

Le Data Warehouse n'est pas un luxe, c'est **la base indispensable** pour toute entreprise data-driven.

---

### ğŸ¯ Valeur dÃ©montrÃ©e sur le projet Olist

| Dimension | RÃ©sultat |
|-----------|----------|
| **Performance** | 25Ã— plus rapide (requÃªtes <200ms vs 5s Pandas) |
| **QualitÃ©** | Concordance 100% (0 perte financiÃ¨re sur 13.6M R$) |
| **MÃ©triques** | 9 KPIs mÃ©tier dÃ©bloquÃ©s (rÃ©tention, LTV, RFM, Pareto...) |
| **Ã‰chelle** | 1.5M lignes brutes â†’ 287K lignes structurÃ©es optimisÃ©es |
| **Infrastructure** | 1 fichier 50MB SQLite (portable, zero-config) |

---

### ğŸ“Š Limites assumÃ©es du projet

| Limite | Justification |
|--------|---------------|
| **SQLite (pas PostgreSQL)** | OK pour <1M lignes, read-only, mono-utilisateur |
| **Vues virtuelles (pas matÃ©rialisÃ©es)** | SQLite ne supporte pas MATERIALIZED VIEW |
| **PrÃ©cision gÃ©o ~2km** | MÃ©diane lat/lng par code postal (OK analyses rÃ©gionales) |
| **Grain article** | Semi-additif sur `order_payment_total` (nÃ©cessite DISTINCT order_id) |

â¡ï¸ Migration PostgreSQL recommandÃ©e si volumÃ©trie > 10M lignes ou concurrence Ã©criture nÃ©cessaire

---

### ğŸ“ PrÃªt Ã  maÃ®triser SQL avancÃ© ?

**Dans les 5 modules suivants**, vous allez apprendre Ã  :

1. **Module 1 - Fondamentaux** : SELECT, WHERE, GROUP BY, JOINs, sous-requÃªtes
2. **Module 2 - Window Functions** : RANK, ROW_NUMBER, LEAD/LAG, NTILE
3. **Module 3 - CTEs & RÃ©cursivitÃ©** : WITH, requÃªtes multi-niveaux, arbres hiÃ©rarchiques
4. **Module 4 - Optimisation** : EXPLAIN, index, matÃ©rialisation, dÃ©normalisation
5. **Module 5 - Cas MÃ©tier Olist** : Ã‰crire les 9 requÃªtes KPI prÃ©sentÃ©es !

**ğŸ¯ Vous allez Ã©crire vous-mÃªme les 9 mÃ©triques SQL** :
- `cohorts_retention.sql` (matrice rÃ©tention par cohorte)
- `rfm_segmentation.sql` (segmentation clients 10 groupes)
- `pareto_sellers.sql` (rÃ¨gle 80/20 sur vendeurs)
- `seller_scoring.sql` (note multi-critÃ¨res)
- ... et 5 autres requÃªtes analytiques avancÃ©es

**CommenÃ§ons par les fondamentaux !** ğŸš€
""").classes('text-gray-300')
