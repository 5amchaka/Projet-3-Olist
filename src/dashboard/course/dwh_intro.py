"""
Introduction d√©taill√©e du Data Warehouse Olist.

6 slides :
1. Contexte Olist (dataset, probl√®mes CSV)
2. Processus ETL (sch√©ma flow)
3. Sch√©ma en √©toile interactif
4. D√©cisions architecturales
5. Avant/Apr√®s (Pandas vs SQL)
6. Justification business
"""

from nicegui import ui


def render_intro_carousel():
    """Affiche l'introduction DWH avec navigation manuelle entre slides."""

    # √âtat de navigation
    current_slide = {'index': 0}
    total_slides = 6

    # Container principal
    slide_container = ui.column().classes('w-full')

    def render_slide(index: int):
        """Affiche le slide √† l'index donn√©."""
        slide_container.clear()

        with slide_container:
            # Progress indicator
            with ui.row().classes('w-full justify-center mb-4'):
                for i in range(total_slides):
                    if i == index:
                        ui.label('‚óè').classes('text-green-400 text-2xl')
                    else:
                        ui.label('‚óã').classes('text-gray-600 text-2xl')

            # Contenu du slide
            with ui.card().classes('w-full p-8 chapter-enter'):
                if index == 0:
                    render_slide_1()
                elif index == 1:
                    render_slide_2()
                elif index == 2:
                    render_slide_3()
                elif index == 3:
                    render_slide_4()
                elif index == 4:
                    render_slide_5()
                elif index == 5:
                    render_slide_6()

            # Navigation
            with ui.row().classes('w-full justify-between mt-4'):
                if index > 0:
                    ui.button('‚Üê Pr√©c√©dent', on_click=lambda: navigate(-1)).props('outline')
                else:
                    ui.label('')  # Spacer

                if index < total_slides - 1:
                    ui.button('Suivant ‚Üí', on_click=lambda: navigate(1)).props('color=primary')
                else:
                    ui.button('Commencer le cours üöÄ', on_click=start_course).props('color=positive')

    def navigate(delta: int):
        """Navigue entre les slides."""
        current_slide['index'] = max(0, min(total_slides - 1, current_slide['index'] + delta))
        render_slide(current_slide['index'])

    def start_course():
        """Redirige vers la premi√®re le√ßon."""
        ui.navigate.to('/presentation/module_1_fundamentals/0')

    # Afficher premier slide
    render_slide(0)


def render_slide_1():
    """Slide 1 : Contexte Olist."""
    ui.label("üéØ Le Dataset Olist").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Dataset E-commerce Br√©silien (2016-2018)

**Olist** est une plateforme e-commerce br√©silienne qui connecte des milliers de vendeurs ind√©pendants avec les plus grandes marketplaces du pays.

### Les chiffres
- üõí **100 000 commandes** sur 24 mois
- üë• **96 000 clients** uniques
- üè™ **3 000 vendeurs** actifs
- üì¶ **32 000 produits** diff√©rents
- üåé **27 √©tats** br√©siliens couverts

### Les donn√©es sources : 8 fichiers CSV
1. `olist_orders_dataset.csv` (99k lignes)
2. `olist_order_items_dataset.csv` (112k lignes)
3. `olist_customers_dataset.csv` (96k lignes)
4. `olist_sellers_dataset.csv` (3k lignes)
5. `olist_products_dataset.csv` (32k lignes)
6. `olist_order_reviews_dataset.csv` (99k lignes)
7. `olist_order_payments_dataset.csv` (103k lignes)
8. `olist_geolocation_dataset.csv` (1M lignes!)

---

## üö® Le probl√®me des CSV bruts

### Impossible d'analyser efficacement
- ‚ùå **Pas de relations** : Pas de cl√©s √©trang√®res, jointures difficiles
- ‚ùå **Duplications** : Informations r√©p√©t√©es (ville cliente copi√©e 50√ó si 50 commandes)
- ‚ùå **Qualit√© variable** : Donn√©es manquantes, formats incoh√©rents
- ‚ùå **Performance** : Chargement complet en m√©moire √† chaque analyse (slow!)
- ‚ùå **Pas d'index** : Recherches lin√©aires O(n) sur 100k lignes

### Exemple concret
**Question m√©tier** : "Quel est le taux de r√©tention des clients par cohorte mensuelle ?"

**Avec CSV** : 150+ lignes de code Pandas, 5 secondes d'ex√©cution, code illisible

**Avec DWH** : 78 lignes SQL, 0.2 secondes, requ√™te claire et r√©utilisable

‚û°Ô∏è **Solution** : Construire un Data Warehouse optimis√©
""").classes('text-gray-300')


def render_slide_2():
    """Slide 2 : Processus ETL."""
    ui.label("‚öôÔ∏è Le Processus ETL").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Extract ‚Üí Transform ‚Üí Load

Notre pipeline de transformation suit les √©tapes classiques de l'ing√©nierie des donn√©es.
""").classes('text-gray-300 mb-4')

    # Sch√©ma Mermaid du flow ETL
    ui.mermaid("""
graph LR
    A[8 CSV Sources] -->|Extract| B[DataFrames Pandas]
    B -->|Transform| C[Cleaning + Engineering]
    C -->|Load| D[(SQLite DWH)]

    style A fill:#e74c3c
    style B fill:#f39c12
    style C fill:#3498db
    style D fill:#27ae60

    C -->|clean_geolocation| C1[D√©doublonner codes postaux]
    C -->|parse_dates| C2[Convertir formats dates]
    C -->|delivery_days| C3[Calculer d√©lais livraison]
    C -->|create_keys| C4[G√©n√©rer cl√©s surrogate]
""").classes('w-full mb-4')

    ui.markdown("""
### 1. **Extract** : Chargement des CSV
```python
orders_df = pd.read_csv("olist_orders_dataset.csv")
items_df = pd.read_csv("olist_order_items_dataset.csv")
# ... 6 autres CSV
```

### 2. **Transform** : Nettoyage et enrichissement

**Op√©rations principales** :
- **`clean_geolocation()`** : D√©doublonner les codes postaux (1M ‚Üí 19k lignes)
- **`parse_dates()`** : Convertir strings ‚Üí datetime ‚Üí format ISO
- **`delivery_days`** : Calculer `delivery_date - order_date` (feature engineering)
- **`create_surrogate_keys()`** : G√©n√©rer cl√©s num√©riques (customer_key, product_key)
- **`fill_missing_values()`** : Imputer valeurs manquantes (modes, moyennes)

**Code snippet** :
```python
def clean_geolocation(df: pd.DataFrame) -> pd.DataFrame:
    \"\"\"D√©doublonne codes postaux (garder mode par groupe).\"\"\"
    return df.groupby('zip_code', as_index=False).agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )
```

### 3. **Load** : Insertion dans SQLite

```python
# Sch√©ma en √©toile : 1 fait + 5 dimensions
fact_orders.to_sql('fact_orders', conn, index=False)
dim_customers.to_sql('dim_customers', conn, index=False)
# ... autres dimensions

# Index strat√©giques
conn.execute("CREATE INDEX idx_orders_date ON fact_orders(order_date)")
conn.execute("CREATE INDEX idx_orders_customer ON fact_orders(customer_key)")
```

‚û°Ô∏è **R√©sultat** : Un DWH queryable en quelques millisecondes
""").classes('text-gray-300')


def render_slide_3():
    """Slide 3 : Sch√©ma en √©toile."""
    ui.label("‚≠ê Sch√©ma en √âtoile").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Mod√©lisation dimensionnelle : Le c≈ìur du DWH

Le sch√©ma en √©toile est le standard pour les Data Warehouses analytiques.
""").classes('text-gray-300 mb-4')

    # Sch√©ma ERD avec Mermaid
    ui.mermaid("""
erDiagram
    fact_orders ||--o{ dim_customers : "customer_key"
    fact_orders ||--o{ dim_sellers : "seller_key"
    fact_orders ||--o{ dim_products : "product_key"
    fact_orders ||--o{ dim_geolocation : "customer_zip_code"
    fact_orders ||--o{ dim_dates : "order_date"

    fact_orders {
        int order_item_id PK
        string order_id
        int customer_key FK
        int seller_key FK
        int product_key FK
        date order_date
        decimal price
        string order_status
        int delivery_days
        int review_score
    }

    dim_customers {
        int customer_key PK
        string customer_id
        string customer_city
        string customer_state
    }

    dim_sellers {
        int seller_key PK
        string seller_id
        string seller_city
        string seller_state
    }

    dim_products {
        int product_key PK
        string product_id
        string category
        decimal weight_g
        decimal volume_cm3
    }

    dim_geolocation {
        string zip_code PK
        string city
        string state
        float lat
        float lng
    }

    dim_dates {
        date date_key PK
        int year
        int month
        int day
        int week
        string month_name
    }
""").classes('w-full mb-4')

    ui.markdown("""
### üìä Cardinalit√©s

| Table | Lignes | R√¥le |
|-------|--------|------|
| **fact_orders** | 112 515 | **Table de faits** (transactions) |
| dim_customers | 96 096 | Attributs clients (ville, √©tat) |
| dim_sellers | 3 095 | Attributs vendeurs |
| dim_products | 32 951 | Cat√©gories, dimensions produits |
| dim_geolocation | 19 015 | Codes postaux d√©doublonn√©s |
| dim_dates | 793 | Calendrier (2016-2018) |

### üîë Grain de la table de faits
**1 ligne = 1 article d'une commande**

Exemple : Commande #123 avec 3 articles ‚Üí 3 lignes dans fact_orders.

**Pourquoi ce grain ?**
- ‚úÖ Permet d'agr√©ger au niveau commande (`GROUP BY order_id`) ou article
- ‚úÖ Conserve le d√©tail maximal (prix unitaire, review par article)
- ‚úÖ Facilite les analyses produit (quel article g√©n√®re le plus de CA ?)

### üéØ Avantages du sch√©ma en √©toile
- ‚úÖ **Jointures simples** : 1 saut de la fact vers chaque dimension
- ‚úÖ **Performance** : Cl√©s surrogate (int) ultra-rapides
- ‚úÖ **Lisibilit√©** : Structure intuitive (centre + branches)
- ‚úÖ **Flexibilit√©** : Ajouter une dimension = 1 colonne FK dans fact
""").classes('text-gray-300')


def render_slide_4():
    """Slide 4 : D√©cisions architecturales."""
    ui.label("üèóÔ∏è D√©cisions Architecturales").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Choix techniques qui rendent le DWH performant

### 1. **Grain : Article vs Commande**

**Option 1 - Grain "Commande"** (rejet√©) :
- ‚ùå Perd le d√©tail par article
- ‚ùå Prix agr√©g√©s (impossible de savoir quel produit co√ªte combien)
- ‚ùå Reviews moyenn√©es (perd la granularit√©)

**Option 2 - Grain "Article"** (‚úÖ choisi) :
- ‚úÖ D√©tail maximal conserv√©
- ‚úÖ Agr√©ger au niveau commande reste possible (`GROUP BY order_id`)
- ‚úÖ Analyses produit facilit√©es

‚û°Ô∏è **D√©cision** : 1 ligne = 1 article (112k lignes dans fact_orders)

---

### 2. **Index Strat√©giques**

Les index acc√©l√®rent les recherches de O(n) ‚Üí O(log n).

**Index cr√©√©s** :
```sql
CREATE INDEX idx_orders_date ON fact_orders(order_date);
CREATE INDEX idx_orders_status ON fact_orders(order_status);
CREATE INDEX idx_orders_customer ON fact_orders(customer_key);
CREATE INDEX idx_orders_seller ON fact_orders(seller_key);
CREATE INDEX idx_orders_product ON fact_orders(product_key);
```

**Impact** :
- Filtrage WHERE sur `order_date` : **100x plus rapide** (0.5ms vs 50ms)
- Jointures fact ‚Üí dimensions : **Instantan√©es** (d√©j√† index√©es)
- Tri ORDER BY : **Optimis√©** (index covering)

**Principe** : Indexer toutes les cl√©s √©trang√®res + colonnes filtr√©es fr√©quemment.

---

### 3. **Vues Mat√©rialis√©es**

Certaines agr√©gations sont r√©utilis√©es fr√©quemment (CA mensuel, cohortes...).

**Vues cr√©√©es** :
```sql
CREATE VIEW v_monthly_sales AS
SELECT
    STRFTIME('%Y-%m', order_date) as order_month,
    SUM(price) as monthly_revenue,
    COUNT(DISTINCT order_id) as nb_orders
FROM fact_orders
WHERE order_status = 'delivered'
GROUP BY order_month;

CREATE VIEW v_customer_cohorts AS
SELECT
    customer_id,
    STRFTIME('%Y-%m', MIN(order_date)) as cohort_month
FROM fact_orders
GROUP BY customer_id;
```

**Avantage** : Requ√™tes complexes deviennent des `SELECT * FROM v_monthly_sales`.

---

### 4. **Cl√©s Surrogate vs Cl√©s Naturelles**

**Cl√© naturelle** : `customer_id` (string UUID 32 chars, 32 bytes)

**Cl√© surrogate** : `customer_key` (integer auto-incr√©ment√©, 4 bytes)

**Impact** :
- ‚úÖ **8x moins d'espace** (4 bytes vs 32)
- ‚úÖ **Jointures plus rapides** (√©galit√© sur int vs string)
- ‚úÖ **Index plus compacts** (B-Tree sur int = optimal)

‚û°Ô∏è **D√©cision** : Toutes les FK utilisent des cl√©s surrogate (customer_key, seller_key, product_key).

---

### 5. **SQLite vs PostgreSQL**

Pourquoi SQLite pour un DWH ?

**Avantages** :
- ‚úÖ **Zero-config** : 1 fichier .db, pas de serveur
- ‚úÖ **Portable** : Copier le .db = copier tout le DWH
- ‚úÖ **Rapide** : Window functions performantes, optimiseur correct
- ‚úÖ **Suffisant** : < 1M lignes = parfait pour SQLite

**Limites** (OK pour notre use case) :
- ‚ùå Pas de concurrence √©criture (read-only en prod = OK)
- ‚ùå Pas de r√©plication (backup fichier = OK)
- ‚ùå Pas de partitionnement (pas n√©cessaire √† 112k lignes)

‚û°Ô∏è **D√©cision** : SQLite est id√©al pour un DWH analytique mono-utilisateur.
""").classes('text-gray-300')


def render_slide_5():
    """Slide 5 : Avant/Apr√®s (Pandas vs SQL)."""
    ui.label("üìä Avant / Apr√®s : Pandas vs SQL").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Comparaison concr√®te sur 2 analyses m√©tier

### Exemple 1 : Matrice de r√©tention par cohorte

**Question** : "Quel % de clients de la cohorte Jan 2017 sont revenus en F√©v, Mars, Avril ?"

#### ‚ùå Avec CSV Pandas (150 lignes, ~5s)

```python
import pandas as pd
from datetime import datetime

# Charger 3 CSV
orders = pd.read_csv("orders.csv")
items = pd.read_csv("order_items.csv")
customers = pd.read_csv("customers.csv")

# Merger
df = items.merge(orders, on='order_id').merge(customers, on='customer_id')

# Parse dates
df['order_date'] = pd.to_datetime(df['order_purchase_timestamp'])
df['order_month'] = df['order_date'].dt.to_period('M')

# Identifier cohorte (mois premi√®re commande)
cohorts = df.groupby('customer_id')['order_month'].min().reset_index()
cohorts.columns = ['customer_id', 'cohort_month']
df = df.merge(cohorts, on='customer_id')

# Calculer delta mois
df['months_since_cohort'] = ((df['order_month'].dt.year - df['cohort_month'].dt.year) * 12 +
                               (df['order_month'].dt.month - df['cohort_month'].dt.month))

# Pivoter
retention = df.groupby(['cohort_month', 'months_since_cohort'])['customer_id'].nunique().unstack(fill_value=0)

# Calculer % r√©tention
retention_pct = retention.div(retention[0], axis=0) * 100

print(retention_pct)
# Temps: ~5 secondes, 150 lignes de code
```

#### ‚úÖ Avec DWH SQL (78 lignes, ~0.2s)

```sql
WITH first_orders AS (
    SELECT
        customer_id,
        CAST(STRFTIME('%Y%m', MIN(order_date)) AS INTEGER) as cohort_month
    FROM fact_orders
    GROUP BY customer_id
),
all_orders AS (
    SELECT DISTINCT
        customer_id,
        CAST(STRFTIME('%Y%m', order_date) AS INTEGER) as order_month
    FROM fact_orders
),
cohort_activity AS (
    SELECT
        f.cohort_month,
        a.order_month,
        (a.order_month / 100 - f.cohort_month / 100) * 12 +
        (a.order_month % 100 - f.cohort_month % 100) as months_since_cohort,
        COUNT(DISTINCT a.customer_id) as active_customers
    FROM first_orders f
    INNER JOIN all_orders a ON f.customer_id = a.customer_id
    GROUP BY f.cohort_month, a.order_month
),
cohort_sizes AS (
    SELECT cohort_month, COUNT(*) as cohort_size
    FROM first_orders
    GROUP BY cohort_month
)
SELECT
    ca.cohort_month,
    ca.months_since_cohort,
    ca.active_customers,
    cs.cohort_size,
    ROUND(ca.active_customers * 100.0 / cs.cohort_size, 1) as retention_pct
FROM cohort_activity ca
INNER JOIN cohort_sizes cs ON ca.cohort_month = cs.cohort_month
WHERE ca.months_since_cohort BETWEEN 0 AND 12
ORDER BY ca.cohort_month, ca.months_since_cohort;
-- Temps: 0.2s, 78 lignes SQL
```

**Gains** :
- ‚ö° **25x plus rapide** (5s ‚Üí 0.2s)
- üìñ **Lisible** : CTEs explicites vs code proc√©dural
- ‚ôªÔ∏è **R√©utilisable** : Sauvegard√© dans `cohorts_retention.sql`

---

### Exemple 2 : Segmentation RFM (Recency, Frequency, Monetary)

#### ‚ùå Avec CSV Pandas (120 lignes, ~3s)

```python
# Calculer RFM par client
rfm = df.groupby('customer_id').agg({
    'order_date': lambda x: (datetime.now() - x.max()).days,  # Recency
    'order_id': 'nunique',  # Frequency
    'price': 'sum'  # Monetary
}).rename(columns={'order_date': 'recency', 'order_id': 'frequency', 'price': 'monetary'})

# Scorer avec quintiles
rfm['r_score'] = pd.qcut(rfm['recency'], 5, labels=False, duplicates='drop') + 1
rfm['f_score'] = pd.qcut(rfm['frequency'].rank(method='first'), 5, labels=False) + 1
rfm['m_score'] = pd.qcut(rfm['monetary'].rank(method='first'), 5, labels=False) + 1

# Classifier
def classify_rfm(row):
    if row['r_score'] >= 4 and row['m_score'] >= 4:
        return 'Champions'
    elif row['r_score'] >= 3 and row['f_score'] >= 3:
        return 'Loyal'
    # ... 8 autres conditions
    else:
        return 'Lost'

rfm['segment'] = rfm.apply(classify_rfm, axis=1)
```

#### ‚úÖ Avec DWH SQL (143 lignes, ~0.5s)

```sql
WITH rfm_raw AS (
    SELECT
        customer_id,
        JULIANDAY('now') - JULIANDAY(MAX(order_date)) as recency_days,
        COUNT(DISTINCT order_id) as frequency,
        SUM(price) as monetary
    FROM fact_orders
    WHERE order_status = 'delivered'
    GROUP BY customer_id
),
rfm_scored AS (
    SELECT
        *,
        NTILE(5) OVER (ORDER BY recency_days ASC) as r_score,
        NTILE(5) OVER (ORDER BY frequency DESC) as f_score,
        NTILE(5) OVER (ORDER BY monetary DESC) as m_score
    FROM rfm_raw
),
rfm_segmented AS (
    SELECT
        *,
        CASE
            WHEN r_score >= 4 AND m_score >= 4 THEN 'Champions'
            WHEN r_score >= 3 AND f_score >= 3 THEN 'Loyal'
            -- ... autres segments
            ELSE 'Lost'
        END as segment
    FROM rfm_scored
)
SELECT * FROM rfm_segmented;
```

**Gains** :
- ‚ö° **6x plus rapide**
- üéØ **NTILE natif** : Pas de gestion des duplicates
- üìä **Window functions** : Plus √©l√©gant que `rank().qcut()`

---

## üéØ Conclusion

| Crit√®re | CSV Pandas | DWH SQL |
|---------|------------|---------|
| **Performance** | 3-5s | 0.2-0.5s |
| **Code** | 120-150 lignes | 78-143 lignes |
| **Lisibilit√©** | ‚ùå Proc√©dural | ‚úÖ D√©claratif (CTEs) |
| **R√©utilisabilit√©** | ‚ùå Script jetable | ‚úÖ Requ√™tes sauvegard√©es |
| **Scalabilit√©** | ‚ùå M√©moire limit√©e | ‚úÖ Index + optimiseur |

‚û°Ô∏è Le DWH SQL est **25x plus rapide** et **2x plus concis** pour des analyses m√©tier complexes.
""").classes('text-gray-300')


def render_slide_6():
    """Slide 6 : Justification business."""
    ui.label("üíº Valeur Business du DWH").classes('text-4xl font-bold mb-4')

    ui.markdown("""
## Pourquoi investir dans un Data Warehouse ?

### üéØ Dimensions m√©tier activ√©es

Le DWH Olist permet d'analyser le business sous **5 dimensions** :

1. **üìÖ Temps** : Tendances mensuelles, saisonnalit√©, cohortes
2. **üåé G√©ographie** : Performance par √©tat/ville (client ET vendeur)
3. **üë• Clients** : Segmentation RFM, LTV, r√©tention, nouveaux vs r√©currents
4. **üè™ Vendeurs** : Scoring multi-crit√®res, Pareto, qualit√© livraison
5. **üì¶ Produits** : Cat√©gories star, panier moyen, cross-sell

**Impossible avec CSV bruts** : Chaque dimension n√©cessite des jointures complexes et des agr√©gations.

---

### üìä M√©triques m√©tier cl√©s d√©bloqu√©es

| M√©trique | Description | Requ√™te SQL |
|----------|-------------|-------------|
| **Taux de r√©tention par cohorte** | % clients revenus M+1, M+2... | `cohorts_retention.sql` |
| **LTV (Lifetime Value)** | CA total par client | `ltv_cohorts.sql` |
| **Taux de conversion** | % visiteurs ‚Üí acheteurs | `new_vs_recurring.sql` |
| **Pareto vendeurs** | Top 20% g√©n√®rent X% du CA | `pareto_sellers.sql` |
| **Panier moyen** | CA / nb commandes | `basket_avg.sql` |
| **NPS (Net Promoter Score)** | % promoteurs - d√©tracteurs | `overview_kpis.sql` |
| **Churn rate** | % clients inactifs > 6 mois | Custom query |

**ROI direct** : Ces KPIs pilotent les d√©cisions strat√©giques (o√π investir, quels produits pousser, quels vendeurs coacher).

---

### ‚ö° Rapidit√© = Agilit√© d√©cisionnelle

**Avant (CSV)** :
- Analyste : 30 min de code Python ‚Üí attendre 5s ‚Üí debugger ‚Üí r√©ex√©cuter...
- Total : **2-3h** pour une analyse ad-hoc
- R√©sultat : **1 analyse par jour** max

**Apr√®s (DWH)** :
- Analyste : 5 min de SQL ‚Üí r√©sultat en 0.2s ‚Üí it√©rer rapidement
- Total : **10-15 min** pour une analyse ad-hoc
- R√©sultat : **10-20 analyses par jour**

‚û°Ô∏è **10x plus de questions business r√©pondues** = d√©cisions data-driven plus rapides.

---

### üîç Complexit√©s impossibles sans DWH

Certaines analyses sont **impossibles** (ou prohibitives) avec CSV Pandas :

#### 1. **Auto-jointures temporelles**
"Clients ayant command√© X puis Y dans les 30 jours suivants" ‚Üí Self-join sur dates.

#### 2. **Window functions complexes**
"Rang du produit par cat√©gorie ET par √©tat" ‚Üí PARTITION BY multi-niveaux.

#### 3. **CTEs r√©cursives**
"Parcours clients sur N commandes" ‚Üí WITH RECURSIVE (pas support√© en Pandas).

#### 4. **Sous-requ√™tes corr√©l√©es optimis√©es**
"Top 3 produits par vendeur" ‚Üí CTE + ROW_NUMBER (vs boucles Pandas).

---

### üí∞ √âconomies directes

**Infrastructure** :
- ‚ùå CSV : Serveur avec 32GB RAM pour charger tout en m√©moire (~‚Ç¨500/mois)
- ‚úÖ DWH : SQLite = 1 fichier 50MB, serveur 2GB RAM (~‚Ç¨50/mois)

**Temps analyste** :
- ‚ùå CSV : 10 analyses/sem √ó 2h = 20h/sem (‚Ç¨2000/mois √† ‚Ç¨100/h)
- ‚úÖ DWH : 50 analyses/sem √ó 15min = 12.5h/sem (‚Ç¨1250/mois)

‚û°Ô∏è **√âconomie** : ‚Ç¨1200/mois (infrastructure + temps)

---

### üöÄ √âvolutivit√©

Le DWH est **futur-proof** :
- ‚úÖ Ajouter une nouvelle dimension (ex: `dim_categories`) = 1 colonne FK dans fact
- ‚úÖ Ajouter une nouvelle m√©trique = 1 nouvelle colonne calcul√©e
- ‚úÖ Migrer vers PostgreSQL si croissance > 10M lignes = schema compatible

**Pandas CSV n'est PAS √©volutif** : Chaque nouvelle source = refactor complet du pipeline.

---

## ‚úÖ Conclusion : DWH = Fondation analytique

Le Data Warehouse n'est pas un luxe, c'est **la base indispensable** pour toute entreprise data-driven.

**Valeur d√©montr√©e** :
- ‚ö° **25x plus rapide** que Pandas CSV
- üìä **10x plus d'analyses** r√©alis√©es
- üí∞ **‚Ç¨1200/mois** √©conomis√©s
- üéØ **Impossible ‚Üí Possible** (analyses complexes)

‚û°Ô∏è **ROI** : 6 mois (investissement initial divis√© par gains mensuels)

---

üéì **Pr√™t √† ma√Ætriser SQL avanc√© ?**

Dans les 5 modules suivants, vous allez apprendre √† :
- √âcrire des requ√™tes analytiques complexes (CTEs, window functions)
- Optimiser les performances (index, EXPLAIN, mat√©rialisation)
- Impl√©menter des cas m√©tier r√©els (RFM, cohortes, Pareto, scoring)

**Commen√ßons par les fondamentaux !** üöÄ
""").classes('text-gray-300')
